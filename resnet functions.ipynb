{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras.layers import merge, Input,Lambda\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "#from imagenet_utils import decode_predictions, preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_bn_relu(filter_size, kernel_size=3, bn=True, relu=True, strides=(1,1), border_mode='same'):\n",
    "    def tmp(input_tensor): \n",
    "        x = Convolution2D(filter_size, kernel_size, kernel_size, border_mode=border_mode, subsample=strides)(input_tensor)\n",
    "        if(bn): x = BatchNormalization()(x)\n",
    "        if(relu): x = Activation('relu')(x)\n",
    "        return x\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def res_bottleneck(filters, kernel_size=3, strides=(1,1), branch=1,\n",
    "                   conv_in_shortcut=False, conv=conv_bn_relu):\n",
    "    def tmp(input_tensor):\n",
    "            if(len(filters)==1):\n",
    "                nb_filter1, nb_filter2, nb_filter3 = filters[0], filters[0], filters[0]*4\n",
    "            else:\n",
    "                nb_filter1, nb_filter2, nb_filter3 = filters[0], filters[1], filters[2]\n",
    "            xx = []\n",
    "            for _ in range(depth):\n",
    "                x = conv(nb_filter1, 1, strides=strides)(input_tensor)\n",
    "                x = conv(nb_filter2, kernel_size)(x)\n",
    "                x = conv(nb_filter3, 1, relu=False)(x)\n",
    "                xx.append(x)\n",
    "            if(conv_in_shortcut): \n",
    "                input_tensor=conv(nb_filter3, 1, strides=strides, relu=False)(input_tensor)\n",
    "            xx.append(input_tensor)\n",
    "            x = merge(xx, mode='sum')\n",
    "            x = Activation('relu')(x)\n",
    "            return x\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def res(filters, kernel_size=3, strides=(1,1), branch = 1,\n",
    "        conv_in_shortcut=False, conv=conv_bn_relu):\n",
    "    def tmp(input_tensor):\n",
    "            nb_filter = filters[0]\n",
    "            xx = []\n",
    "            for _ in range(branch):\n",
    "                x = conv(nb_filter, kernel_size, strides=strides)(input_tensor)\n",
    "                x = conv(nb_filter, kernel_size, relu=False)(x)\n",
    "                xx.append(x)\n",
    "            if(conv_in_shortcut): \n",
    "                input_tensor=conv(nb_filter, 1, strides=strides, relu=False)(input_tensor)\n",
    "            xx.append(input_tensor)\n",
    "            x = merge(xx, mode='sum')\n",
    "            x = Activation('relu')(x)\n",
    "            return x\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def shakeres(filters, kernel_size=3, strides=(1,1), branch = 2,\n",
    "        conv_in_shortcut=False, conv=conv_bn_relu):\n",
    "    def tmp(input_tensor):\n",
    "            nb_filter = filters[0]\n",
    "            x1 = conv(nb_filter, kernel_size, strides=strides)(input_tensor)\n",
    "            x1 = conv(nb_filter, kernel_size, relu=False)(x1)\n",
    "            x2 = conv(nb_filter, kernel_size, strides=strides)(input_tensor)\n",
    "            x2 = conv(nb_filter, kernel_size, relu=False)(x2)\n",
    "            alpha = K.random_uniform(K.shape(x1),0,1)\n",
    "            y1 = (Lambda(lambda x:x*alpha ))(x1)\n",
    "            y2 = (Lambda(lambda x:x*(1-alpha)))(x2)\n",
    "            y = merge([y1,y2], mode='sum')\n",
    "            if(conv_in_shortcut): \n",
    "                input_tensor=conv(nb_filter, 1, strides=strides, relu=False)(input_tensor)\n",
    "            x = merge([input_tensor,y], mode='sum')\n",
    "            x = Activation('relu')(x)\n",
    "            return x\n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def block(filters, depth, strides=(2,2), kernel_size=3, branch=1,\n",
    "          res=res, conv=conv_bn_relu):\n",
    "    def tmp(input_tensor):\n",
    "        x = res(filters, kernel_size,  strides=strides, conv_in_shortcut=True, branch=branch, conv=conv)(input_tensor)\n",
    "        for _ in range(depth-1):\n",
    "            x = res(filters, kernel_size, conv=conv, branch=branch)(x)\n",
    "        return x\n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def blocks(classes, depths, filters=[64,128,256,512], kernel_size=3, branch=1,\n",
    "           res=res, conv=conv_bn_relu):\n",
    "    def tmp(input_tensor):\n",
    "        x = block( [filters[0]], depths[0], kernel_size=kernel_size, strides=(1, 1), branch=branch,\n",
    "                 res=res, conv=conv)(input_tensor)\n",
    "        for i in range(1,len(depths)):\n",
    "            x = block([filters[i]], depths[i], strides=(2, 2), kernel_size=kernel_size, branch=branch,\n",
    "                     res=res, conv=conv)(x)\n",
    "        _,_,H,W = x.get_shape()\n",
    "        H,W = H.value, W.value\n",
    "        x = AveragePooling2D((H, W), name='avg_pool')(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, activation='softmax')(x)\n",
    "        return x\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imagenet():\n",
    "    classes = 1000\n",
    "    input_shape = (3, 224, 224)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = conv(x, 64, 7, strides=(2,2),border_mode='valid')\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = blocks(x, classes, [3,4,6,3])\n",
    "    return Model(img_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cifar(depth):   \n",
    "    assert(((depth - 2) % 6) == 0)\n",
    "    n = int((depth - 2) / 6)\n",
    "    classes = 10\n",
    "    input_shape = (3, 32, 32)\n",
    "    print(' | ResNet-' + str(depth) + ' CIFAR-10')\n",
    "    img_input = Input(shape=input_shape)\n",
    "    x = blocks(classes, [n,n,n],[16,32,64],branch=2,res=shakeres)(img_input)\n",
    "    return Model(img_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | ResNet-20 CIFAR-10\n"
     ]
    }
   ],
   "source": [
    "model = cifar(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 3, 32, 32)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 200\n",
    "data_augmentation = True\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# The CIFAR10 images are RGB.\n",
    "img_channels = 3\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 236s - loss: 1.7230 - acc: 0.3549 - val_loss: 1.6356 - val_acc: 0.4149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efe4867c0b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('Not using data augmentation.')\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=1,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
